---
title: "p8105_hw2_ls3751"
author: "Liucheng Shi"
output: github_document
---

_packages required_
```{r setup, message = FALSE}
library(tidyverse)
library(readxl)
```


## Problem 1

### 1.1 Mr. Trashwheel dataset

```{r, message = F, warning = F}
trashwheel_df = 
	read_xlsx(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "Mr. Trash Wheel",
		range = cell_cols("A:N")) %>% 
	janitor::clean_names() %>% 
	drop_na(dumpster) %>% 
	mutate(
		sports_balls = round(sports_balls),
		sports_balls = as.integer(sports_balls)
	)
```

### 1.2 read precipitation data 2017/2018

```{r}
precip_2018 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2018 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2018) %>% 
	relocate(year)
precip_2017 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2017 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2017) %>% 
	relocate(year)
```

### 1.3 combine annual precipitation dataframes

```{r}
month_df = 
	tibble(
		month = 1:12,
		month_name = month.name
	)
precip_df = 
	bind_rows(precip_2018, precip_2017)
precip_df =
	left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. In this dataset:

* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.



## Problem 2

### 2.1 Dataset overview

```{r load the dataset, message = F, warning = F, collapse = T}
nyc_transit_df = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
                          col_types = "cccddccccccccccccccccclclcccddcc") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = T, "NO" = F)) %>% 
  mutate(vending = recode(vending, "YES" = T, "NO" = F))
```

This dataset contains information about NYC subway MTA, including the location, the lines each station served, infrastructure status and so on. The `r ncol(nyc_transit_df)` variables are `r names(nyc_transit_df)`.

The data cleaning process are as follow:

*   read in the dataset and clean the variable names so that they all display as snake case.
*   use select to pull variables of interest, and use mutate (recode) to covert character variables to logical variables.

The dimension of the dataset is `r nrow(nyc_transit_df)` rows * `r ncol(nyc_transit_df)` columns. 

THe dataset is not tidy yet. Routine number and routine name seems to be clustered together that rows did not represent the observations, and columns are not variables.



### 2.2 Distinct stations and ADA compliant

```{r distinguish by name and line, collapse = T}
nyc_distinct = nyc_transit_df %>% 
  distinct(station_name, line, .keep_all = T)

distinct_ada = filter(nyc_distinct, ada == TRUE)

no_vending_entry = filter(nyc_transit_df, vending == F) %>%
                  filter(entry == T)
no_vending = filter(nyc_transit_df, vending == F)
```

*   The number of the __distinct stations__ is `r nrow(nyc_distinct)`.
*   Among them, `r nrow(distinct_ada)` stations are ADA compliant
*   Proportion of stations that have no vending allow entrance is `r count(no_vending_entry)/count(no_vending)`.


### 2.3 Distinct stations serve A & ADA

_Reformat the route number and route name_

```{r}
nyc_transit_tidy = pivot_longer(nyc_distinct, route1:route11,
             names_to = "route_name",
             values_to = "route_number",
             names_prefix = "route")
```

*   There are `r nrow(filter(nyc_transit_tidy, route_number == "A"))` distinct stations serve the A train.  
*   There are `r nrow(filter(nyc_transit_tidy, route_number == "A", ada == TRUE))` distinct stations that A train are ADA compliant.



## Problem 3

### 3.1 Data cleaning (pols_month):

*   _break up mon into year, month, and day_.
*   _replace month number with month name, create a president variable_. 
*   _remove prez_dem, prez_gop, and day_.

```{r, message = F}
polmonth_df = read_csv("./data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year", "month", "day")) %>% 
  mutate(president = case_when(
    prez_gop == 1 ~ "gop",
    prez_dem == 1 ~ "dem"),
         year = as.numeric(year),
         day = as.numeric(day),
         month = as.numeric(month))
polmonth_tidy = polmonth_df %>% 
  left_join(month_df, by = "month") %>% 
  mutate(month = month_name) %>% 
  select(-prez_dem, -prez_gop, -day, -month_name)
```

This dataset contains `r nrow(polmonth_tidy)` records about politicians' and presidents' status. 
The dimension of pols_month is [`r dim(polmonth_tidy)`], with `r ncol(polmonth_tidy)` variables collected from `r min(pull(polmonth_tidy,year))` to `r max(pull(polmonth_tidy,year))`.
The variables are `r names(polmonth_tidy)`.

### 3.2 Data cleaning (snp):

*   _use a similar process_.
*   _make year and month leading columns_.

```{r, message = F}
snp_df = read_csv("./data/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, c("month", "day", "year")) %>% 
  mutate(month = as.numeric(month), 
          day = as.numeric(day), 
          year = as.numeric(year))
snp_tidy = snp_df %>% 
  left_join(month_df, by = "month") %>% 
  mutate(month = month_name) %>% 
  select(year, month, close)
```

This dataset contains `r nrow(snp_tidy)` S&P stock market index values, which the variable close indicates the value of S&P index when market is closed at that day. 
The dimension of snp is [`r dim(snp_tidy)`], with `r ncol(snp_tidy)` variables collected from `r min(pull(snp_tidy,year))` to `r max(pull(snp_tidy,year))`.
The variables are `r names(snp_tidy)`.

### 3.3 Data cleaning (unemployment):

```{r, message = F}
unemployment_df = read_csv("./data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(jan:dec,
    names_to = "month",
    values_to = "unemployment") %>% 
  mutate(year = as.integer(year))
month_Lower = tibble(
  month = c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
  month_name = month.name
  )
unemployment_tidy = unemployment_df %>% 
  left_join(month_Lower, by = "month") %>% 
  mutate(month = month_name) %>% 
  select(year, month, unemployment)
```

This dataset contains `r nrow(unemployment_tidy)` unemployment rates recorded monthly each year. 
The dimension of unemployment is [`r dim(unemployment_tidy)`], with `r ncol(unemployment_tidy)` variables collected from `r min(pull(unemployment_tidy,year))` to `r max(pull(unemployment_tidy,year))`.
The variables are `r names(unemployment_tidy)`.

### 3.4 Join the three datasets accordingly

```{r}
analy_df = 
  left_join(polmonth_tidy,snp_tidy, by = c("year","month")) %>% 
  left_join(unemployment_tidy, by = c("year","month"))
```


Since we start merging with pols_month dataset, we get `r nrow(analy_df)` observations, equals to the rows of pols_month dataset. 
The dimension of the final_df is [`r dim(analy_df)`],with `r ncol(analy_df)` variables collected from `r min(pull(analy_df,year))` to `r max(pull(analy_df,year))`. Since pols_month dataset starts from 1947 which is earlier than the other two datasets, we can observe many missing data in "close" and "unemployment" associate to the years 1947-1949.

